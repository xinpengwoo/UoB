{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDEbF2x0UnuW"
   },
   "source": [
    "# Text-Classification with Naive Bayes\n",
    "This week you have learned about text classfication using ML algorithm Naive Bayes. In the lab this week, you will learn how to go through the steps of training a text-classifier using some of the techniques talked about in the lecture this week.\n",
    "\n",
    "We will use [NLTK](https://www.nltk.org/) and [Scikit-learn](https://scikit-learn.org/stable/) as we go through the lab sheet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Ppq4e_tZLsj"
   },
   "source": [
    "## Import your data\n",
    "\n",
    "The dataset you will be using can be downloaded from this [link](https://archive.ics.uci.edu/ml/machine-learning-databases/00228/). Download the zip file and make sure you read through the readme file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GgckxzLncWsN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Md8gfnZkly-",
    "outputId": "5512a14c-cf57-4c68-ebd7-53303fd17b5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a total of 5572 examples.\n"
     ]
    }
   ],
   "source": [
    "print(f'We have a total of {len(data)} examples.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbqbXgoalR1v"
   },
   "source": [
    "Now change the label column in the dataframe so that we have:\n",
    "* 0 for ham\n",
    "* 1 for spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Fau8q3Tm1rl"
   },
   "source": [
    "We want to also explore if we have a class imbalance and what our data looks like. Make sure you understand what you are classifying before diving in. \n",
    "\n",
    "Use the power of pandas dataframe to count the number of examples for each of the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UN5RKadTZPXM"
   },
   "source": [
    "## Preprocess your data\n",
    "Now that we have seen what our data looks like, we can begin to think about how we might pre-process our data. We can do a simple pre-processing and then, if needed, we can do more, such as lemmatise etc.\n",
    "\n",
    "1. words are lower case\n",
    "2. tokenize\n",
    "3. stop-word removal\n",
    "4. punctuation and non-alpha character removal\n",
    "5. Lemmatise the words in the text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3QfdMjj1Gt8i"
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lPFva10jAYVE"
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tZtUu6QfGoyB"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9getKXqnJc5H"
   },
   "source": [
    "We make everything lower case and tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BD_uw9wlL3aW"
   },
   "source": [
    "Remove stopwords, non alphabetic characters and punctuation, and lemmatise the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VAwt_wCDFCU"
   },
   "source": [
    "Compare the original text to the preprocessed text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5PU18VEZTNN"
   },
   "source": [
    "## Split the data\n",
    "Now we will split our data using sklearn into our train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pFM_3jVtCWIs"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6_tsX2YZe-8"
   },
   "source": [
    "## Feature selection\n",
    "\n",
    "Let's experiment with feature selection. We will test two different methods for this:\n",
    "\n",
    "\n",
    "1.   Word frequency\n",
    "2.   Mutual Information - Tfidf\n",
    "\n",
    "Implement both. We will train and test our algorithms with both to see which one works better for our data.\n",
    "\n",
    "Hint: this is where we are vectorizing our data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pM56c7VVKGZS"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUbpJBcnL94I"
   },
   "source": [
    "Take a look to see what our feature names are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JK0_aQ0YKAZM"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6iGUv3MaIB2"
   },
   "source": [
    "## Train the Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9tEQTVYPUkP"
   },
   "source": [
    "Train the model using the data vectorized using the count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N5BJG2BIPdFR"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxvNrkMlPbmt"
   },
   "source": [
    "Train the model using the data vectorized using the tfidf vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBlvT1vkbMBy"
   },
   "source": [
    "## Test and Results\n",
    "Now that we have a trained classifier, let's test to see if it generalises well to unseen examples. Let's compare the F-1 score for the two feature selection methods we used earlier.\n",
    "\n",
    "Make sure to note which one seems to work beter for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jTeFw3ekUinU"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4WJNn0WS2pE"
   },
   "source": [
    "Test the count model on the test data. Then print the confusion matrix and classification report comparing the gold labels to predictions from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SA1aAkRMSpWE"
   },
   "source": [
    "Test the tfidf model on the test data. Then print the confusion matrix and classification report comparing the gold labels to predictions from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9T3MWW6hccif"
   },
   "source": [
    "# Bonus: Multiclass classification\n",
    "\n",
    "Now that you have implemented a binary classifier, let's try to do the same but this time for multiple classes. We will be working with the ______ dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37GgM-QJTVR-"
   },
   "source": [
    "Use the [20 newsgroups dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html) available on sklearn dataset library.\n",
    "\n",
    "Implement naive bayes but for 5 classes (out of the 20 avaialable) on this dataset. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
