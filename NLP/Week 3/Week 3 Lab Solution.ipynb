{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import datetime\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following \"spoof newspaper headlines\", such as:  \n",
    "\n",
    "British Left Waffles on Falkland Islands, and Juvenile Court to Try Shooting Defendant.  \n",
    "\n",
    "Manually tag these headlines to see if knowledge of the [part-of-speech tags](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html) removes the ambiguity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('British', 'NNPS'),\n",
       " ('Left', 'VB'),\n",
       " ('Waffles', 'NNPS'),\n",
       " ('on', 'IN'),\n",
       " ('Falkland', 'NNP'),\n",
       " ('Islands', 'NNPS')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline1 = \"British/NNPS Left/VB Waffles/NNPS on/IN Falkland/NNP Islands/NNPS\"  #one potential interpretation.\n",
    "[nltk.tag.str2tuple(t) for t in headline1.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Juvenile', 'NOUN'),\n",
       " ('Court', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Try', 'VERB'),\n",
       " ('Shooting', 'ADJ'),\n",
       " ('Defendant', 'NOUN')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here TRY means to examine evidence in court and decide whether sb is innocent or guilty \n",
    "headline2 = 'Juvenile/NOUN Court/NOUN to/PRT Try/VERB Shooting/ADJ Defendant/NOUN'       #one potential interpretation.\n",
    "[nltk.tag.str2tuple(t) for t in headline2.split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize and tag the below given sentence by using ([using NLTK POS Tagger](https://www.nltk.org/api/nltk.tag.pos_tag.html)) and [spaCy](https://spacy.io/usage/linguistic-features)  \n",
    "\n",
    "\"They wind back the clock, while we chase after the wind\".  \n",
    "\n",
    "What different pronunciations and parts of speech are involved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('They', 'PRP'),\n",
       " ('wind', 'VBP'),\n",
       " ('back', 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('clock', 'NN'),\n",
       " (',', ','),\n",
       " ('while', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('chase', 'VBP'),\n",
       " ('after', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('wind', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'They wind back the clock, while we chase after the wind.'\n",
    "nltk.pos_tag(nltk.word_tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>explain pos</th>\n",
       "      <th>explain tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>They</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>pronoun, personal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wind</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBP</td>\n",
       "      <td>verb</td>\n",
       "      <td>verb, non-3rd person singular present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>back</td>\n",
       "      <td>ADP</td>\n",
       "      <td>RP</td>\n",
       "      <td>adposition</td>\n",
       "      <td>adverb, particle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>determiner</td>\n",
       "      <td>determiner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clock</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>noun</td>\n",
       "      <td>noun, singular or mass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>punctuation</td>\n",
       "      <td>punctuation mark, comma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>while</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>IN</td>\n",
       "      <td>subordinating conjunction</td>\n",
       "      <td>conjunction, subordinating or preposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>we</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>pronoun, personal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chase</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBP</td>\n",
       "      <td>verb</td>\n",
       "      <td>verb, non-3rd person singular present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>after</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>adposition</td>\n",
       "      <td>conjunction, subordinating or preposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>determiner</td>\n",
       "      <td>determiner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>wind</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>noun</td>\n",
       "      <td>noun, singular or mass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>punctuation</td>\n",
       "      <td>punctuation mark, sentence closer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     text    pos  tag                explain pos  \\\n",
       "0    They   PRON  PRP                    pronoun   \n",
       "1    wind   VERB  VBP                       verb   \n",
       "2    back    ADP   RP                 adposition   \n",
       "3     the    DET   DT                 determiner   \n",
       "4   clock   NOUN   NN                       noun   \n",
       "5       ,  PUNCT    ,                punctuation   \n",
       "6   while  SCONJ   IN  subordinating conjunction   \n",
       "7      we   PRON  PRP                    pronoun   \n",
       "8   chase   VERB  VBP                       verb   \n",
       "9   after    ADP   IN                 adposition   \n",
       "10    the    DET   DT                 determiner   \n",
       "11   wind   NOUN   NN                       noun   \n",
       "12      .  PUNCT    .                punctuation   \n",
       "\n",
       "                                  explain tag  \n",
       "0                           pronoun, personal  \n",
       "1       verb, non-3rd person singular present  \n",
       "2                            adverb, particle  \n",
       "3                                  determiner  \n",
       "4                      noun, singular or mass  \n",
       "5                     punctuation mark, comma  \n",
       "6   conjunction, subordinating or preposition  \n",
       "7                           pronoun, personal  \n",
       "8       verb, non-3rd person singular present  \n",
       "9   conjunction, subordinating or preposition  \n",
       "10                                 determiner  \n",
       "11                     noun, singular or mass  \n",
       "12          punctuation mark, sentence closer  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "sent = nlp(\"They wind back the clock, while we chase after the wind.\")\n",
    "cols = [\"text\", \"pos\", \"tag\", \"explain pos\", \"explain tag\"]\n",
    "\n",
    "rows = []\n",
    "for token in sent:\n",
    "  row = token.text, token.pos_, token.tag_, spacy.explain(token.pos_), spacy.explain(token.tag_)\n",
    "  rows.append(row)\n",
    "df = pd.DataFrame(rows, columns=cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task-3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write programs to read and process the [NLTK Brown Corpus](https://www.nltk.org/howto/corpus.html) and perform the followig tasks:\n",
    "\n",
    "- Get and display a list of all categories of the brown corpus.\n",
    "- Get and display the tokenized and tagged version of the \"news\" category.\n",
    "- Get and display the sentence segmented, tokenized, and tagged version of the \"news\" category.\n",
    "- Print the first 5 words, and the first 2 sentences.\n",
    "- Get and display the set of all the tags in the brown corpus.\n",
    "- Get and display the set of all the tags in the universal tagset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The first 5 words in the tokenized and tagged version are: [('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL')]\n",
      "\n",
      "The first 2 sentences in the sentence segmented, tokenized and tagged version are [[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')], [('The', 'AT'), ('jury', 'NN'), ('further', 'RBR'), ('said', 'VBD'), ('in', 'IN'), ('term-end', 'NN'), ('presentments', 'NNS'), ('that', 'CS'), ('the', 'AT'), ('City', 'NN-TL'), ('Executive', 'JJ-TL'), ('Committee', 'NN-TL'), (',', ','), ('which', 'WDT'), ('had', 'HVD'), ('over-all', 'JJ'), ('charge', 'NN'), ('of', 'IN'), ('the', 'AT'), ('election', 'NN'), (',', ','), ('``', '``'), ('deserves', 'VBZ'), ('the', 'AT'), ('praise', 'NN'), ('and', 'CC'), ('thanks', 'NNS'), ('of', 'IN'), ('the', 'AT'), ('City', 'NN-TL'), ('of', 'IN-TL'), ('Atlanta', 'NP-TL'), (\"''\", \"''\"), ('for', 'IN'), ('the', 'AT'), ('manner', 'NN'), ('in', 'IN'), ('which', 'WDT'), ('the', 'AT'), ('election', 'NN'), ('was', 'BEDZ'), ('conducted', 'VBN'), ('.', '.')]]\n",
      "\n",
      "The set of all original tags in the brown orpus is: {'PPL', 'IN-HL', 'NN', 'DT+BEZ', 'NN$-TL', 'BEDZ*', 'PP$-TL', 'CC-TL', 'FW-JJ', 'OD', 'ABX', 'NP-TL-HL', 'NN-NC', 'NPS-HL', 'DO', 'JJR', 'FW-DT', 'BEG', 'FW-JJ-TL', 'WPS', 'HVD', '.-HL', 'FW-IN-TL', 'CC', 'BER-HL', 'IN', 'DOZ*', 'BEZ*', 'FW-IN', 'PPSS', 'PP$$', 'QL', 'MD', 'BE-HL', 'UH', 'BEZ', 'VBN-HL', 'PPSS+HV', 'WPS+BEZ', 'DOD*', 'PPSS+MD', 'PPSS+BEM', 'DTS', \"'\", 'FW-AT-HL', 'CD$', 'PPSS-HL', 'RB-TL', 'NP$', 'QL-TL', 'HVD-HL', 'DTX', 'NR-HL', 'NPS$', 'DO*', 'AP$', 'BEN', 'ABL', 'PN', 'NN-HL', 'JJ-NC', 'CD', '(-HL', 'DO-HL', 'VBD-HL', 'RB+BEZ', 'JJS', 'QLP', 'CS', 'VBZ-HL', 'DT-HL', 'PPS+MD', 'WQL', 'JJS-TL', 'FW-NN', 'MD+HV', 'JJ', 'NPS$-TL', 'FW-AT-TL', 'FW-NNS', 'TO-TL', 'VB-HL', 'OD-TL', 'VB+PPO', 'FW-IN+AT-TL', 'FW-*', 'PPLS', 'EX', 'HVZ*', 'FW-WDT', 'NPS', 'VBG-TL', 'FW-IN+NN', 'PN$', ',', 'JJ-HL', 'BE', 'DTI', 'NN-TL-HL', 'PPS', 'NNS-TL', 'RP', 'NP-HL', 'PPSS+BER', 'NNS$-TL', 'BEDZ', 'AP', 'VBZ', 'PPO', 'JJT', '(', 'FW-CC', 'NN$-HL', 'VB-TL', 'CC-HL', 'FW-PP$-NC', 'HV', 'JJT-HL', 'RP-HL', 'NP$-TL', '*-HL', 'BER*', 'JJR-HL', 'NR', 'AP-TL', 'EX+BEZ', 'HVZ', 'HVN', 'UH-TL', 'FW-NN-TL', 'NR$', 'VBD', 'VB', 'NNS', 'VBN-TL-HL', 'NPS-TL', 'NP+BEZ', 'NR$-TL', 'MD*-HL', 'BED*', 'FW-AT', 'VBN-TL', 'PPS+BEZ-HL', 'AT-HL', 'RBR', 'VBG', 'NNS-HL', 'WDT', 'NP-TL', 'CD-HL', 'WPO', 'TO', 'RB-HL', 'BEDZ-HL', 'MD*', 'BER-TL', 'RB$', '``', '.', 'DT$', 'PP$', 'ABN', 'WRB', 'ABN-HL', 'AP-HL', 'BER', 'CS-HL', 'TO-HL', 'FW-VB-NC', 'HVD*', 'RB', \"''\", 'NN-TL', 'PN-HL', 'BED', 'NR-TL', 'PPS+BEZ', 'MD-TL', 'VBG-HL', 'FW-VB', ':', 'IN-TL', 'CD-TL', ')-HL', 'VBD-TL', 'OD-HL', ',-HL', 'VBN', 'MD-HL', 'JJR-NC', '--', 'WP$', 'AT-TL', 'NNS$-HL', 'BEZ-HL', 'AT', 'DOD', 'JJ-TL', ')', 'JJR-TL', 'BEM', 'DOZ', 'RBT', 'DT', 'DTI-HL', 'WDT+BEZ', ':-HL', 'NNS$', 'FW-IN+NN-TL', 'NN$', 'PN+HVZ', 'HVG', '*', 'FW-CD', 'PPSS+HVD', 'NP', 'PPS+HVZ', 'NNS-TL-HL'}\n",
      "\n",
      "The set of universal tags is: {'CONJ', 'VERB', 'NOUN', 'PRT', 'DET', 'PRON', 'NUM', 'ADP', 'X', '.', 'ADJ', 'ADV'}\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all categories of the brown corpus\n",
    "brown.categories()\n",
    "\n",
    "# Get the tokenized and tagged version of the \"news\" category\n",
    "brown_twords = brown.tagged_words(categories='news')\n",
    "\n",
    "# Get the sentence segmented, tokenized, and tagged version of the \"news\" category\n",
    "brown_tsents = brown.tagged_sents(categories='news')\n",
    "\n",
    "# Print the first 5 words\n",
    "print(\"\\nThe first 5 words in the tokenized and tagged version are: {}\".format(brown_twords[:5]))\n",
    "print(\"\\nThe first 2 sentences in the sentence segmented, tokenized and tagged version are {}\".format(brown_tsents[:2]))\n",
    "\n",
    "# Get the set of all the tags in the brown corpus\n",
    "brown_tags = set([tag for (token,tag) in brown_twords])\n",
    "print(\"\\nThe set of all original tags in the brown orpus is: {}\".format(brown_tags))\n",
    "\n",
    "# Get the set of all the tags in the universal tagset\n",
    "brown_utwords = brown.tagged_words(categories='news',tagset='universal')\n",
    "universal_tags = set([tag for (token,tag) in brown_utwords])\n",
    "print(\"\\nThe set of universal tags is: {}\".format(universal_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-4:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write programs to process the Brown Corpus and find answers to the following questions:\n",
    "\n",
    "Which nouns are more common in their plural form, rather than their singular form? (Only consider regular plurals, formed with the -s suffix.)\n",
    "Which word has the greatest number of distinct tags. What are they, and what do they represent?\n",
    "List tags in order of decreasing frequency. What do the 20 most frequent tags represent?\n",
    "Which tags are nouns most commonly found after? What do these tags represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ConcatenatedCorpusView' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38865/2173913466.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbrown_tagged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagged_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConditionalFreqDist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrown_tagged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ConcatenatedCorpusView' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "brown_tagged = brown.tagged_words()\n",
    "cfd = nltk.ConditionalFreqDist(brown_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Aid', 'outburst', 'spectator', 'Crowd', 'endearment', 'spoil', 'Proprietorship', 'interface', 'tactic', 'outbreak', 'fuck', 'nothing', 'Bird', 'polyphosphate', 'tavern', 'Reporter', 'tree', 'serpent', 'Area', 'Senator', 'supporter', 'organism', 'Thank', 'makeshift', 'spoke', 'vital', 'determinant', 'indicator', 'limit', 'filbert', 'Institution', 'offensive', 'silo', 'wandering', 'ruler', 'carrier', 'happening', 'active', 'cell', 'reservation', 'periodical', 'manifestation', 'Conference', 'nun', 'one', 'youngster', 'postulate', 'parasite', 'prolusion', 'turnpike', 'compulsive', 'Northerner', 'Gain', 'milligram', 'epithet', 'follower', 'saving', 'burglar', 'highlight', 'technique', 'Avocado', 'publisher', 'Fund', 'trait', 'plate', 'Idea', 'sock', 'ray', 'parameter', 'diver', 'sailor', 'banker', 'Thing', 'Record', 'synthetic', 'adverb', 'dolphin', 'spacer', 'leak', 'speculation', 'Hazard', 'loyalist', 'wrestle', 'realtor', 'Vineyard', '1890', 'doing', 'modification', 'silicate', 'Set', 'survivor', 'two', 'linguist', 'transformer', 'cartoon', 'map', 'Result', 'error', 'Banker', 'canon', 'specialist', 'vocal', 'spade', 'Flat', 'Mine', 'ethic', 'pageant', 'comet', 'deep', 'aberration', 'treasure', 'basic', 'rule', 'dipole', 'Car', 'salon', 'participant', 'prop', 'pirate', 'motorist', 'fee', 'crystallite', 'fan', 'Trader', 'contributor', 'Scholar', 'revelling', 'occupant', 'constituent', 'Realtor', 'poem', 'ear', 'puddle', 'reporter', 'thank', 'Chart', 'giggle', 'loin', 'Station', 'compliment', 'Circumstance', 'mammal', 'jerking', 'headline', 'libertie', 'slave', 'hub', 'noun', 'batterie', 'tonic', 'Representative', 'Culture', 'limitation', 'escapade', 'Want', 'meter', 'Team', 'House', 'vine', 'rite', 'Other', 'integral', 'eclipse', 'rocket', 'admonition', 'dealing', 'intangible', 'Make', 'stockholder', 'observation', 'adherent', 'grotesque', 'peer', 'Head', 'movie', 'personage', 'Sound', 'picker', 'pore', 'superlative', 'Regulation', 'Nation', 'word', 'native', 'gassing', 'System', 'Estimate', 'urging', 'adjective', 'normal', 'explosive', 'Glaze', 'Reef', 'Plan', 'institution', 'grouping', 'Indication', 'Superintendent', 'investigator', 'destroyer', 'Judge', 'megaton', 'bun', 'lobule', 'elder', 'Look', 'stocking', 'Official', 'runner', 'Design', 'million', 'Course', 'convert', 'Star', 'competitor', 'immigrant', 'resistor', 'emotion', 'protease', 'creeper', 'visitor', 'Trooper', 'conqueror', 'enzyme', 'towel', 'employe', 'object', 'savage', 'Corporation', 'appointee', 'ill', 'Regular', 'expenditure', 'Camera', 'painting', '1940', 'azalea', 'barbarian', 'migrant', 'installation', 'Start', 'Missile', 'toy', 'theologian', 'Solution', 'rendition', 'pajama', '2-year-old', 'aerial', 'restriction', 'silhouette', 'triplet', 'pamphlet', 'vista', 'scripture', 'nail', 'bubble', 'Invitation', 'meteor', 'stump', 'pier', 'oilseed', 'bruise', 'homosexual', 'armament', 'wary', 'steroid', 'booklet', 'Eye', 'cookie', 'compound', 'grocer', 'final', 'outsider', 'anterior', 'Leave', 'Governor', 'moth', 'axe', 'skylight', 'ailment', 'sole', 'mountain', 'courtier', 'ten', 'geologist', 'imagining', 'shim', 'intellectual', 'schoolmate', 'valve', 'member', 'toe', 'dune', 'byproduct', 'gasp', 'gadget', 'lashing', 'leg', 'memoir', 'interrelationship', 'lobe', 'hoof', 'decree', 'eatable', 'Letter', 'tektite', 'chunk', 'newlywed', 'auditor', 'ideal', 'listener', 'promoter', 'rut', 'Associate', 'Bottom', 'four', 'musing', 'ripple', 'passenger', 'proceeding', 'catalog', 'bound', 'landmark', 'Oil', 'dictate', 'people', 'clod', 'pebble', 'preserve', 'deduction', 'farmer', 'Command', 'trump', 'Session', 'striving', 'ballistic', 'heroic', 'tablespoon', 'headache', 'Junior', 'Judgment', 'psychologist', 'believer', 'diehard', 'Hurt', 'patron', 'Problem', 'applicant', 'yard', 'bomber', 'franc', 'rattlesnake', 'modern', 'crackpot', 'friend', 'disclosure', 'cleaner', 'bough', 'anionic', 'bidder', 'reagent', 'romantic', 'psychiatrist', 'stunt', 'inmate', 'ether', 'bitter', 'entertainer', 'regular', 'calorie', 'maker', 'fete', '1960', 'Change', 'extra', 'particle', 'walnut', 'Feeling', 'Illustration', 'feature', 'Person', 'paw', 'channel', 'bird', 'ellipsoid', 'nightclub', 'trader', 'motive', 'deductible', 'eyelid', 'Employee', 'lyric', 'resultant', 'national', 'dollar', 'advisor', 'marina', 'employee', 'drier', 'norm', 'flip', 'contour', 'grape', 'prisoner', 'acre', 'obligation', 'infestation', 'ad', 'Step', 'comedie', 'wrinkle', 'suitor', 'bushel', 'adapter', 'Original', 'guest', 'verb', 'atom', 'being', 'Evening', 'greeting', 'Student', 'condition', 'bug', 'footstep', 'cuff', 'Case', 'furnishing', 'terminal', 'confine', 'Fraction', 'moral', 'import', 'arm', 'citizen', 'Export', 'eccentric', 'heel', 'boo', 'stray', 'two-week', 'Artist', 'Application', 'antiquarian', 'step', 'leaflet', 'remark', 'cloud', 'undergraduate', 'grenade', 'sediment', 'emerald', 'live', 'probe', 'duffer', 'doll', 'leading', 'bronchiole', 'proponent', 'diagonal', 'affiliation', 'pillar', 'Market', 'counterpart', 'sensitive', 'like', 'honeybee', 'rebel', 'seeker', 'secant', 'cheekbone', 'investor', 'Moral', 'gymnast', 'theatrical', 'teenager', 'upland', 'referral', 'Number', 'extractor', 'concentrate', 'improvisation', 'rogue', 'laurel', 'Survey', 'characteristic', 'jowl', 'overture', 'nutrient', 'fat', 'commune', 'Liberal', 'imperfection', 'Investigation', 'lark', 'Flower', 'headquarter', 'acoustic', 'Officer', 'lag', 'practitioner', 'scientist', 'Return', 'initial', 'gust', 'nude', 'commercial', 'bud', 'allowance', 'concessionaire', '1930', 'purge', 'senator', 'vow', 'symptom', 'spiritual', 'antecedent', 'insecticide', 'bumblebee', 'mine', 'observer', 'tough', 'standard', 'accomplishment', 'conservative', 'tribe', 'ion', 'colored', 'Experiment', 'Dean', 'manual', 'flower', 'shrub', 'Snake', 'Citizen', 'cop', 'revenue', 'exploit', 'scholar', 'cosmetic', 'directive', 'ton', 'comrade', 'centimeter', 'coordinate', 'Song', 'metaphysical', 'Force', 'giant', 'servant', 'camper', 'biscuit', 'Dealer', 'carving', 'shaving', 'Report', 'absolute', 'premise', 'Statue', 'revision', 'innocent', 'crater', 'planner', 'implication', 'white', 'chant', 'bribe', 'Sign', 'rigid', 'Plane', 'hike', 'volunteer', 'Chestnut', 'conformist', 'lapel', 'Guest', 'classic', 'consequence', 'narcotic', 'subversive', 'epicycle', 'abolitionist', 'initiate', 'Member', 'pound', 'custom', 'dimension', 'surmise', 'infidel', 'supermarket', 'implement', 'guerrilla', 'specific', 'chore', 'gallant', 'therefore', 'trapping', 'Operation', 'injunction', 'conjugate', 'eyebrow', 'dropping', 'event', 'transient', 'thousandth', 'lilac', 'inboard', 'stamp', 'notable', 'planet', 'subsystem', 'boasting', 'miner', 'photographer', 'urn', 'topic', 'weed', 'document', 'precept', 'Graduate', 'Score', 'Say', 'Poet', 'speculator', 'sweeping', 'loudspeaker', 'gallon', '1920', 'Dog', 'prime', 'antic', 'chop', 'Intangible', 'batten', 'recrimination', 'guardian', 'feather', 'retailer', 'recruit', 'robber', 'professional', 're-run', 'foreigner', 'Advertiser', 'bomb', 'omission', 'descendant', 'liberal', 'tangent', 'defender', 'resource', 'endowment', 'chromatic', 'commoner', 'relation', 'probing', 'Magnum', 'nerve', 'Payment', 'term', 'mechanic', 'pacer', 'submarine', 'Demon', 'coping', 'dependent', 'rating', 'thicket', 'Trustee', 'these', 'scandal', 'clove', 'medal', 'component', 'vendor', 'fragment', 'vitamin', 'angel', 'disadvantage', 'drawing', 'Measurement', 'aspiration', 'vase', 'winning', 'trimming', 'employer', 'advertisement', 'traitor', 'expectation', '45-degree', 'singer', 'ingredient', 'Criminal', 'universal', 'monosyllable', 'colonial', 'slack', 'Color', 'Lot', 'expert', 'dislocation', 'sweet', 'stain', 'perturbation', 'underwriter', 'pheasant', 'Sponsor', 'steward', 'scholastic', 'Town', 'controller', 'costume', 'simple', 'shipment', 'firecracker', 'arrangement', 'suburb', 'projection', 'Diet', 'tenth', 'hugging', 'troop', 'Relative', 'Dream', 'Cost', 'bristle', 'oyster', 'deltoid', 'racketeer', 'Line', 'attribute', 'drug', 'incumbent', 'inflection', 'Book', 'organ', 'out', 'element', 'prerogative', 'swelling', 'overall', 'gunner', 'libertarian', 'mug', 'claw', 'grad', 'teen-ager', 'dynamic', 'rib', 'helmet', 'siren', 'leave', 'representative', 'tear', 'herpetologist', 'performer', 'card', 'dose', 'wrestling', 'Individual', 'barrier', 'hitter', 'nuance', 'wing', 'Sentiment', 'receipt', 'Boat', 'Girl', 'intermediate', 'affair', 'surfactant', 'Bullet', 'cube', 'defect', 'poster', 'enthusiast', 'Observer', 'fundamental', 'critter', 'Example', 'short', 'teen', 'catkin', 'moderate', 'tidbit', 'manufacturer', 'dresser', 'Painting', 'circumstance', 'robot', 'fingering', 'experiment', 'wave', 'month', 'allusion', 'alcoholic', 'deliberation', 'congratulation', 'skate', 'Method', 'surrounding', 'bond', 'worker', 'frank', 'Highway', 'peacock', 'drum', 'lower', 'incompetent', 'sensor', 'Bid', 'shaker', 'Teacher', 'Film', 'relative', 'twin', 'riddle', 'evocation', 'assessor', 'ghoul', 'variable', 'orchard', 'critic', 'incidental', 'spike', 'anti-Communist', 'trustee', 'associate', 'elephant', 'carrot', 'Flock', 'concession', 'gymnastic', 'Picture', 'finding', 'regulation', 'candidate', 'soldier', 'ant', 'Test', 'broker', 'titter', 'duck', 'minute', 'Farmer', 'closeup', 'Thousand', 'bracket', 'wrap', 'Year', 'curl', 'rein', 'slipper', 'taxpayer', 'limb', 'complication', 'billion', 'spice', 'sport', 'sacrament', 'belonging', 'finger', 'instruction', 'trouser', 'sag', 'nostril', 'method', 'vault', 'burn', 'hit', 'wavelength', 'lip', 'overhang', 'star', 'export', 'propagandist', 'rupee', 'third', 'asset', 'Expenditure', 'instrumental', 'voter', 'shareholder', 'hundred', 'mile', 'weapon', 'aye', 'weave', 'vehicle', 'jewel', 'villain', 'interval', 'Pagan', 'customer', 'demon', 'draper', 'delegate', '1950', 'shred', 'leader', 'sore', 'politician', 'caller', 'other', 'additive', 'antagonist', 'extract', 'scenic', 'banshee', 'plastic', 'pledge', 'vineyard', 'watershed', 'gutter', 'predecessor', 'ramification', 'grower', 'survivalist', 'insurgent', 'smelt', 'gut', 'sale', 'bifocal', 'Appeal', 'denomination', 'fathom', 'bee', 'bootlegger', 'cape', 'bean', 'ligand', 'plaque', 'Interview', 'Writer', 'liter', 'peasant', 'casual', 'win', 'syllable', 'musician', 'Cow', 'proceed', 'fund', 'clothe', 'Drum', 'pinning', 'measurement', 'Order', 'negotiation', 'sonata', 'egg', 'topping', 'year', 'disciple', 'no', 'contraceptive', 'fighter', 'colleague', 'dividend', 'neighbor', 'specie', 'brothel', 'internationalist', 'more', 'independent', 'sausage', 'fin', 'technician', 'stair', 'skipper', 'strap', 'Train', 'mean', 'generalization', 'adviser', 'mill', 'Loan', 'pink', 'factor', 'up', 'tank', 'nut', 'rim-fire', 'Apologie', 'merchant', 'kenning', 'redcoat', 'paragraph', 'secularist', 'hue', 'airfield', 'gram', 'flare', 'Doctor', 'disc', 'bevel', 'legislator', 'Development', 'cart', 'rodent', 'spewing', 'irregular', 'supervisor', 'shunt', 'researcher', 'gangster', 'bite', 'subordinate', 'yacht', 'shoe', 'vegetable', 'sneaker', 'Share', 'brake', 'Attorney', 'commissioner', 'panel', 'tentacle', 'Wire', \"'60\", 'Orange', 'official', 'player', 'cutter', '90-degree', 'athletic', 'lodging', 'Speaker', 'Play', 'repulsion', 'five', 'accommodation', 'Connection', 'fabric', 'abstract', 'authorization', 'tick', 'progression', 'creature', 'hydride', 'Ship', 'aspect', 'fill-in', 'swell', 'invader', 'hinge', 'specification', 'incompatible', 'warrior', 'duct', 'hostage', 'commitment', 'buyer', 'item', 'maneuver', 'leaving', 'molecule', 'spouse', 'trailer', 'Increase', 'hour', 'insect', 'Marina', 'down', 'marking', 'Name', 'cardinal', 'Model', 'outboard', 'eye', 'sedan', 'product', 'Track', 'barricade', 'lament', 'favorite', 'Coconut', 'defendant', 'earning', 'cooperative', 'aborigine', 'blossom', 'classmate', '1970', 'backyard', 'kissing', 'Traveler', 'qualification', 'alloy', 'odd', 'tranquilizer', 'pupil', 'boot', 'knuckle', 'snag', 'solid', 'student', 'knee', 'generalist', 'consonant', 'deviant', 'thug', 'thousand', 'Reading', 'Cocktail', 'Reference', 'surrealist', 'groove', 'requirement', 'mystic', 'lay', 'monitor', 'Job', 'Advance', 'tenant', 'teamster', 'superior', 'resident', 'dystopia', 'noble', 'three', 'meteorite', 'sailboat', 'binder', 'parent', 'remain', 'Correction', 'Measure', 'Pilot', 'Strike', 'polymer', 'microorganism', 'thing', 'locale', 'Fight', 'Zero', 'cipher', 'Boy', 'dealer', 'appliance', 'Abstraction', 'collaborator', 'forecast', 'Investor', 'facet', 'settler', 'mortal', 'Direction', 'appropriation', 'soybean', 'predisposition', 'feud', 'lung', 'song', 'working', 'Question', 'Seed', 'user', 'hopeful'}\n"
     ]
    }
   ],
   "source": [
    "# Which nouns are more common in their plural form, rather than their singular form? \n",
    "# (Only consider regular plurals, formed with the -s suffix.)\n",
    "\n",
    "common_plural = set()\n",
    "for word in set(brown.words()):\n",
    "    if cfd[word+'s']['NNS'] > cfd[word]['NN']:\n",
    "        common_plural.add(word)\n",
    "print(common_plural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'that'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which word has the greatest number of distinct tags. What are they, and what do they represent?\n",
    "\n",
    "tag_dict = {k:len(cfd[k]) for k in cfd}\n",
    "greatest = max(tag_dict, key=lambda key: tag_dict[key])\n",
    "\n",
    "greatest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NN', 152470),\n",
       " ('IN', 120557),\n",
       " ('AT', 97959),\n",
       " ('JJ', 64028),\n",
       " ('.', 60638),\n",
       " (',', 58156),\n",
       " ('NNS', 55110),\n",
       " ('CC', 37718),\n",
       " ('RB', 36464),\n",
       " ('NP', 34476),\n",
       " ('VB', 33693),\n",
       " ('VBN', 29186),\n",
       " ('VBD', 26167),\n",
       " ('CS', 22143),\n",
       " ('PPS', 18253),\n",
       " ('VBG', 17893),\n",
       " ('PP$', 16872),\n",
       " ('TO', 14918),\n",
       " ('PPSS', 13802),\n",
       " ('CD', 13510)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List tags in order of decreasing frequency. What do the 20 most frequent tags represent?\n",
    "\n",
    "helper_list = [t for (_, t) in brown_tagged]    # extract the tags to a list \n",
    "fd = nltk.FreqDist(helper_list)\n",
    "fd.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IN', '.', ',', 'CC', 'NN', 'NNS', 'VBD', 'CS', 'MD', 'BEZ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which tags are nouns most commonly found after? What do these tags represent?\n",
    "\n",
    "word_tag_pairs = nltk.bigrams(brown_tagged)\n",
    "noun_after = [b[1] for (a, b) in word_tag_pairs if a[1].startswith('NN')]\n",
    "fdist = nltk.FreqDist(noun_after)\n",
    "[tag for (tag, _) in fdist.most_common(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-5:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a unigram tagger ([on Brown Corpus news categories](https://www.nltk.org/howto/corpus.html)) and run it on the below given test text:  \n",
    "\n",
    "test_text = ['hello', 'world', 'natural', 'language', 'processing']  \n",
    "\n",
    "Observe that some words are not assigned a tag. Why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hello', None),\n",
       " ('world', 'NN'),\n",
       " ('natural', 'JJ'),\n",
       " ('language', 'NN'),\n",
       " ('processing', 'NN')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "unigram_tagger = nltk.UnigramTagger(brown_tagged_sents)\n",
    "\n",
    "test_text = ['hello', 'world', 'natural', 'language', 'processing']\n",
    "unigram_tagger.tag(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words doesn't appear in the training text, and therefore the tagger can't speculate the word's tag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-6:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the [NLTK default tagger](https://www.nltk.org/book/ch05.html#:~:text=4.1-,The%20Default%20Tagger,-The%20simplest%20possible), tag the following sentence with most frequent tag in the corpus:  \n",
    "\n",
    "\"the quick brown fox jumped over the lazy dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence tagged with default tagger: [('the', 'NN'), ('quick', 'NN'), ('brown', 'NN'), ('fox', 'NN'), ('jumped', 'NN'), ('over', 'NN'), ('the', 'NN'), ('lazy', 'NN'), ('dog', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# Default tagger\n",
    "\n",
    "# Get the sentence segmented and tokenized version of \"news\"\n",
    "# This is the non-part of speech tagged version that we will be tagging\n",
    "brown_sents = brown.sents(categories='news')\n",
    "\n",
    "# Get a list of all tags in the corpus\n",
    "tags = [tag for (word, tag) in brown.tagged_words(categories='news')]\n",
    "\n",
    "# Get the most frequent tag in the corpus\n",
    "most_frequent_tag = nltk.FreqDist(tags).max()\n",
    "\n",
    "# Configure a default tagger\n",
    "# The default tagger assigns the same \"default\" tag to every token in the corpus\n",
    "# We configure it to annotate with the most frequent tag\n",
    "default_tagger = nltk.DefaultTagger(most_frequent_tag)\n",
    "\n",
    "my_sent = \"the quick brown fox jumped over the lazy dog\".split()\n",
    "print(\"The sentence tagged with default tagger: {}\".format(default_tagger.tag(my_sent)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-7:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the([Brown Corpus news categories](https://www.nltk.org/howto/corpus.html)), train and evaluate the following built-in taggers:\n",
    "- [Unigram Tagger](https://www.nltk.org/book/ch05.html)\n",
    "- [Bigram Tagger](https://www.nltk.org/book/ch05.html)\n",
    "- [Trigram Tagger](https://www.nltk.org/book/ch05.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The first sentence, tagged with affix tagger: [('The', None), ('Fulton', 'NP'), ('County', 'NN'), ('Grand', 'NP'), ('Jury', None), ('said', None), ('Friday', 'NR'), ('an', None), ('investigation', 'NN'), ('of', None), (\"Atlanta's\", 'NP$'), ('recent', 'NN'), ('primary', 'JJ'), ('election', 'NN'), ('produced', 'VBN'), ('``', None), ('no', None), ('evidence', 'NN'), (\"''\", None), ('that', None), ('any', None), ('irregularities', 'NNS'), ('took', None), ('place', 'NN'), ('.', None)]\n",
      "\n",
      "The accuracy of the affix tagger on the corpus is: 0.26\n",
      "\n",
      "The first sentence, tagged with unigram tagger: [('The', 'AT'), ('Fulton', None), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'JJ'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', None), ('took', 'VBD'), ('place', 'NN'), ('.', '.')]\n",
      "\n",
      "The accuracy of the unigram tagger on the corpus is: 0.83\n",
      "\n",
      "The first sentence, tagged with bigram tagger: [('The', 'AT'), ('Fulton', None), ('County', None), ('Grand', None), ('Jury', None), ('said', None), ('Friday', None), ('an', None), ('investigation', None), ('of', None), (\"Atlanta's\", None), ('recent', None), ('primary', None), ('election', None), ('produced', None), ('``', None), ('no', None), ('evidence', None), (\"''\", None), ('that', None), ('any', None), ('irregularities', None), ('took', None), ('place', None), ('.', None)]\n",
      "\n",
      "The accuracy of the bigram tagger on the corpus is: 0.1\n",
      "\n",
      "The first sentence, tagged with trigram tagger: [('The', 'AT'), ('Fulton', None), ('County', None), ('Grand', None), ('Jury', None), ('said', None), ('Friday', None), ('an', None), ('investigation', None), ('of', None), (\"Atlanta's\", None), ('recent', None), ('primary', None), ('election', None), ('produced', None), ('``', None), ('no', None), ('evidence', None), (\"''\", None), ('that', None), ('any', None), ('irregularities', None), ('took', None), ('place', None), ('.', None)]\n",
      "\n",
      "The accuracy of the trigram tagger on the corpus is: 0.06\n"
     ]
    }
   ],
   "source": [
    "# Import taggers\n",
    "from nltk import DefaultTagger, AffixTagger, UnigramTagger, BigramTagger, TrigramTagger\n",
    "\n",
    "# We will split the corpus to train and test\n",
    "test_corpus = brown_tsents[:1000]\n",
    "train_corpus = brown_tsents[1000:]\n",
    "\n",
    "# Train the affix tagger\n",
    "affix_tagger = AffixTagger(train_corpus)\n",
    "\n",
    "# Tag the corpus with the affix tagger\n",
    "affix_sents = affix_tagger.tag_sents(brown_sents)\n",
    "\n",
    "# Print the first sentence and accuracy\n",
    "print(\"\\nThe first sentence, tagged with affix tagger: {}\".format(affix_sents[0]))\n",
    "print(\"\\nThe accuracy of the affix tagger on the corpus is: {}\".format(round(affix_tagger.evaluate(test_corpus),2)))\n",
    "\n",
    "\n",
    "# Train the unigram tagger\n",
    "unigram_tagger = UnigramTagger(train_corpus)\n",
    "\n",
    "# Tag the corpus with the unigram tagger\n",
    "uni_sents = unigram_tagger.tag_sents(brown_sents)\n",
    "\n",
    "# Print the first sentence and accuracy\n",
    "print(\"\\nThe first sentence, tagged with unigram tagger: {}\".format(uni_sents[0]))\n",
    "print(\"\\nThe accuracy of the unigram tagger on the corpus is: {}\".format(round(unigram_tagger.evaluate(test_corpus),2)))\n",
    "\n",
    "\n",
    "# Train the bigram tagger\n",
    "bigram_tagger = BigramTagger(train_corpus)\n",
    "\n",
    "# Tag the corpus with the bigram tagger\n",
    "bi_sents = bigram_tagger.tag_sents(brown_sents)\n",
    "\n",
    "# Print the first sentence and accuracy\n",
    "print(\"\\nThe first sentence, tagged with bigram tagger: {}\".format(bi_sents[0]))\n",
    "print(\"\\nThe accuracy of the bigram tagger on the corpus is: {}\".format(round(bigram_tagger.evaluate(test_corpus),2)))\n",
    "\n",
    "\n",
    "# Train the trigram tagger\n",
    "trigram_tagger = TrigramTagger(train_corpus)\n",
    "\n",
    "# Tag the corpus with the trigram tagger\n",
    "tri_sents = trigram_tagger.tag_sents(brown_sents)\n",
    "\n",
    "tri_sents = trigram_tagger.tag_sents(brown_sents)\n",
    "\n",
    "# Print the first sentence and accuracy\n",
    "print(\"\\nThe first sentence, tagged with trigram tagger: {}\".format(tri_sents[0]))\n",
    "print(\"\\nThe accuracy of the trigram tagger on the corpus is: {}\".format(round(trigram_tagger.evaluate(test_corpus),2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
