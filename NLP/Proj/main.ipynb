{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d86e0613",
   "metadata": {},
   "source": [
    "# 1. Perprocess\n",
    "## 1.1 parse XML\n",
    "use BeautifulSoup to parse XML file, output with pandas dataframe \"sentence, E#A, sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d1371924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseXML(path):\n",
    "    with open(path) as xmldata:\n",
    "        soup = BeautifulSoup(xmldata, \"xml\")\n",
    "    # Create empty lists to store the extracted data\n",
    "    sentence_ids = []\n",
    "    texts = []\n",
    "    categories = []\n",
    "    polarities = []\n",
    "    # Loop through the 'sentence' elements and extract the necessary information\n",
    "    for sentence in soup.find_all('sentence'):\n",
    "        opinions = sentence.find('Opinions')\n",
    "        if opinions is not None:\n",
    "            s_categories = []\n",
    "            s_polarities = []\n",
    "            for opinion in opinions.find_all('Opinion'):\n",
    "                s_categories.append(opinion['category'])\n",
    "                s_polarities.append(opinion['polarity'])\n",
    "            categories.append(s_categories)\n",
    "            polarities.append(s_polarities)\n",
    "        else:\n",
    "            continue\n",
    "        sentence_ids.append(sentence['id'])\n",
    "        texts.append(sentence.find('text').text)           \n",
    "\n",
    "    # Create a pandas dataframe from the extracted data\n",
    "    df = pd.DataFrame({'Sentence ID': sentence_ids,\n",
    "                       'text': texts,\n",
    "                       'label': categories,\n",
    "                       'polarity': polarities})\n",
    "    print(f'{path.split(\"/\")[-1]} has been parsed. The number of sentences with opinions is '\n",
    "          f\"{len(soup.find_all('Opinions'))}({len(soup.find_all('sentence'))}).\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "52983518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseXML_p2(path):\n",
    "    with open(path) as xmldata:\n",
    "        soup = BeautifulSoup(xmldata, \"xml\")\n",
    "    # Create empty lists to store the extracted data\n",
    "    review_rids = []\n",
    "    categories = []\n",
    "    polarities = []\n",
    "    for review in soup.find_all('Review'):\n",
    "        s_categories = []\n",
    "        s_polarities = []\n",
    "        for opinion in review.find_all('Opinion'):\n",
    "            if opinion is not None:\n",
    "                s_categories.append(opinion['category'])\n",
    "                s_polarities.append(opinion['polarity'])\n",
    "        categories.append(s_categories)\n",
    "        polarities.append(s_polarities)\n",
    "        review_rids.append(review['rid'])   \n",
    "            \n",
    "\n",
    "    # Create a pandas dataframe from the extracted data\n",
    "    df = pd.DataFrame({'Review RID': review_rids,\n",
    "                       'label': categories,\n",
    "                       'polarity': polarities})\n",
    "    print(f'{path.split(\"/\")[-1]} has been parsed. The number of reviews with opinions is '\n",
    "          f\"{len(soup.find_all('Review'))}({len(df['label'])}).\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "158ec316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data analysis\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Split categories and create new rows\n",
    "# df_copy = df.copy()\n",
    "# split_categories = df_copy['Category'].str.split(',')\n",
    "# df_copy = df_copy.assign(Category=split_categories).explode('Category')\n",
    "\n",
    "# # Get the unique categories and their frequencies\n",
    "# category_counts = df_copy['Category'].value_counts()\n",
    "# #top_categories = category_counts.head(50)\n",
    "\n",
    "# # Plot the frequencies in descending order\n",
    "# category_counts.plot(kind='barh')\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.title('Category Frequencies')\n",
    "# plt.xlabel('Frequency')\n",
    "# plt.ylabel('Category')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8301b3c",
   "metadata": {},
   "source": [
    "## 1.2 tokenisation, (stopwords,punc removal), lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "381ae0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenisation(data):\n",
    "    tokenised_data = [word_tokenize(sentence) for sentence in data]\n",
    "    return tokenised_data\n",
    "\n",
    "\n",
    "def remove_stopwords(data):\n",
    "    stopwords = stopwords.words('english')\n",
    "    filtered_words = [[word for word in sentence if word.lower() not in stopwords] for sentence in data]\n",
    "    return filter_words\n",
    "#print(stopwords.words('english'))\n",
    "def remove_punctuation(data):\n",
    "    text = [[word for word in sentence if re.sub(r'[^\\w\\s]+', '', word).isalnum()] for sentence in data]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b3ce357",
   "metadata": {},
   "outputs": [],
   "source": [
    "##lemmatization\n",
    "from nltk import stem\n",
    "def lemmatization(data):\n",
    "    wnl = stem.WordNetLemmatizer()\n",
    "    lematized = [[wnl.lemmatize(word) for word in sentence] for sentence in tokenised_data]\n",
    "    return lematized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89dc9ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = df['Text'].values.tolist()\n",
    "#data = tokenisation(data)\n",
    "#data = remove_stopwords(data)\n",
    "#data = remove_punctuation(data)\n",
    "#data = lemmatization(data)\n",
    "#data = [[word.lower() for word in sentence] for sentence in data]\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93a6da9",
   "metadata": {},
   "source": [
    "# 2. Part 1 - Sentence-level Aspect Based Sentiment Analysis\n",
    "\n",
    "+ Features - unigrams, tfidf, .etc \n",
    "+ Model - Logistic Regression Classifier with threshold t\n",
    "\n",
    "## 2.1 Features for Catagory Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "962b306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.tag import pos_tag\n",
    "# pos_data = [pos_tag(sentence,tagset='universal') for sentence in data]\n",
    "# print(pos_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee38f9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8da64739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_bow_around_verb(sentences):\n",
    "    sentence_list = []\n",
    "    verb_bow_list = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        verb_bow = []\n",
    "        pos_tags = nltk.pos_tag(sentence)\n",
    "\n",
    "        verbs = [word for word, pos in pos_tags if pos.startswith('VB')]\n",
    "\n",
    "        if len(verbs) > 0:\n",
    "            verb = verbs[0]\n",
    "            verb_index = sentence.index(verb)\n",
    "\n",
    "            for i in range(max(0, verb_index - 5), verb_index):\n",
    "                if pos_tags[i][1].startswith('JJ') or pos_tags[i][1].startswith('RB') or pos_tags[i][1].startswith('NN'):\n",
    "                    verb_bow.append(sentence[i])\n",
    "\n",
    "            for i in range(verb_index + 1, min(verb_index + 6, len(sentence))):\n",
    "                if pos_tags[i][1].startswith('JJ') or pos_tags[i][1].startswith('RB') or pos_tags[i][1].startswith('NN'):\n",
    "                    verb_bow.append(sentence[i])\n",
    "\n",
    "        sentence_list.append(sentence)\n",
    "        verb_bow_list.append(verb_bow)\n",
    "\n",
    "    df = pd.DataFrame({'Sentence': sentence_list, 'BoW around Verb': verb_bow_list})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5a99fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_bow_at_end_of_sentence(sentences):\n",
    "    sentence_list = []\n",
    "    end_of_sentence_bow_list = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        end_of_sentence_bow = []\n",
    "        pos_tags = nltk.pos_tag(sentence)\n",
    "\n",
    "        for i in range(len(pos_tags)-1, max(len(pos_tags)-6, -1), -1):\n",
    "            if pos_tags[i][1].startswith('JJ') or pos_tags[i][1].startswith('RB'):\n",
    "                end_of_sentence_bow.append(sentence[i])\n",
    "\n",
    "        sentence_list.append(sentence)\n",
    "        end_of_sentence_bow_list.append(end_of_sentence_bow)\n",
    "\n",
    "    df = pd.DataFrame({'Sentence': sentence_list, 'BoW at End of Sentence': end_of_sentence_bow_list})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f98aafb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(text):\n",
    "    # Tokenize the text using NLTK's word_tokenize function\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove punctuation\n",
    "    tokens = [word for word in tokens if re.sub(r'[^\\w\\s]+', '', word).isalnum()]\n",
    "    # Remove stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    # Convert tokens to lowercase\n",
    "    tokens = [token.lower() for token in tokens]   \n",
    "    return tokens\n",
    "\n",
    "def feature_unigram(df, df_t):    \n",
    "    # Create a CountVectorizer instance to compute unigram counts\n",
    "    count_vectorizer = CountVectorizer(tokenizer=custom_tokenizer,max_features=1000)\n",
    "    # Fit and transform the sentences to obtain the unigram count features\n",
    "    count_matrix = count_vectorizer.fit_transform(df['text'])\n",
    "    count_matrix_t = count_vectorizer.transform(df_t['text'])\n",
    "    # Convert the count matrix to a dataframe with appropriate column names\n",
    "    count_df = pd.DataFrame(count_matrix.toarray(), columns=count_vectorizer.get_feature_names())\n",
    "    count_df_t = pd.DataFrame(count_matrix_t.toarray(), columns=count_vectorizer.get_feature_names())\n",
    "    return count_df, count_df_t\n",
    "\n",
    "def feature_Tfidf(df, df_t):\n",
    "    # Create a TfidfVectorizer instance to compute TF-IDF features\n",
    "    tfidf_vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer)\n",
    "    # Fit and transform the sentences to obtain the TF-IDF features\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df['text'])\n",
    "    tfidf_matrix_t = tfidf_vectorizer.transform(df_t['text'])\n",
    "    # Convert the TF-IDF matrix to a dataframe with appropriate column names\n",
    "    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names())\n",
    "    tfidf_df_t = pd.DataFrame(tfidf_matrix_t.toarray(), columns=tfidf_vectorizer.get_feature_names())\n",
    "    return tfidf_df, tfidf_df_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c58123",
   "metadata": {},
   "source": [
    "## 2.2 Logistic Regression Classifier for Catagory Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb949a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def catagory_extraction_LogisticRegressionClf():\n",
    "    #data preprocessing\n",
    "    Laptops_Train_p1 = parseXML(\"./data/Laptops_Train_p1.xml\")\n",
    "    Laptops_Test_p1_gold = parseXML(\"./data/Laptops_Test_p1_gold.xml\")\n",
    "\n",
    "    train = pd.DataFrame({'text': Laptops_Train_p1['Text'],\n",
    "                          'label': Laptops_Train_p1['Categories']})\n",
    "    test = pd.DataFrame({'text': Laptops_Test_p1_gold['Text'],\n",
    "                         'label': Laptops_Test_p1_gold['Categories']})\n",
    "\n",
    "    # Concatenate the original dataframe with the unigram count dataframe and the TF-IDF dataframe\n",
    "    unigram_train, unigram_test = feature_unigram(train, test)\n",
    "    tfidf_train, tfidf_test = feature_Tfidf(train, test)\n",
    "    x_train = pd.concat([unigram_train, tfidf_train], axis=1)\n",
    "    x_test = pd.concat([unigram_test, tfidf_test], axis=1)\n",
    "    # x_train = unigram_train\n",
    "    # x_test = unigram_test\n",
    "\n",
    "    # Convert the labels into binary arrays\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y = mlb.fit_transform(train['label'])\n",
    "    y_test = mlb.transform(test['label'])\n",
    "    # Create a dataframe for the binary label arrays\n",
    "    y_train = pd.DataFrame(y, columns=mlb.classes_)\n",
    "    y_test = pd.DataFrame(y_test, columns=mlb.classes_)\n",
    "    \n",
    "    # Create an instance of LogisticRegression\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    y_pred = np.zeros(y_test.shape)\n",
    "    # Iterate through each label and train a separate binary classifier\n",
    "    for i in range(y_train.shape[1]):\n",
    "        label = mlb.classes_[i]\n",
    "        print(\"Training classifier for label:\", label)\n",
    "        # Fit the model on the training data for the current label\n",
    "        clf.fit(x_train, y_train.iloc[:, i])\n",
    "        # Predict the probabilities of the current label for the testing data\n",
    "        y_pred_prob = clf.predict_proba(x_test)[:, 1] # Use probabilities of positive class (1)\n",
    "\n",
    "        # Set the threshold for category assignment\n",
    "        threshold = 0.2\n",
    "\n",
    "        # Generate predicted labels based on threshold\n",
    "        y_pred_labels = np.where(y_pred_prob >= threshold, 1, 0)\n",
    "\n",
    "        # Add predicted labels to the corresponding column in the binary label array\n",
    "        y_pred[:, i] = y_pred_labels.tolist()\n",
    "\n",
    "#     # Calculate accuracy\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Generate classification report\n",
    "    report = classification_report(y_test, y_pred, zero_division=1)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "    \n",
    "    test_predicted_labels = mlb.inverse_transform(binary_labels)    \n",
    "    return test_predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1da0f622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#catagory_extraction_LogisticRegressionClf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726298ad",
   "metadata": {},
   "source": [
    "## 2.3 Features for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "141f228b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_expansion(df):\n",
    "    original_labels = df['label'].tolist()\n",
    "    original_polarities = df['polarity'].tolist()\n",
    "    \n",
    "    # ==advanced indexing==\n",
    "    reps = [len(val) for val in df['label']]\n",
    "    df = df.loc[np.repeat(df.index.values, reps)]\n",
    "    \n",
    "    df['label'] = [item for sublist in original_labels for item in sublist]\n",
    "    df['polarity'] = [item for sublist in original_polarities for item in sublist]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def dataframe_undoexpansion(y_pred, test):\n",
    "    y_pred = pd.DataFrame({'polarity': y_pred})\n",
    "    y_pred = inverse_numerical_rep(y_pred['polarity'])\n",
    "    y_pred = y_pred.tolist()\n",
    "    y_aligned = []\n",
    "    for index, row in test.iterrows():\n",
    "        sublist = []\n",
    "        for i in range(len(row['polarity'])):\n",
    "            sublist.append(y_pred.pop(0))\n",
    "        y_aligned.append(sublist)\n",
    "    test_pred = test.copy()\n",
    "    test_pred['polarity'] = y_aligned\n",
    "    return test_pred\n",
    "\n",
    "def onehotting(x_train, x_test):\n",
    "    # Convert 'label' column in x_train and x_test to one-hot encoding\n",
    "    x_train_onehot = pd.get_dummies(x_train['label'], prefix='class')\n",
    "    x_test_onehot = pd.get_dummies(x_test['label'], prefix='class')\n",
    "\n",
    "    # Get the columns that are missing in x_test_onehot\n",
    "    missing_cols = set(x_train_onehot.columns) - set(x_test_onehot.columns)\n",
    "    for col in missing_cols:\n",
    "        x_test_onehot[col] = 0\n",
    "\n",
    "    # Reorder the columns in x_test_onehot to match the column names in x_train_onehot\n",
    "    x_test_onehot = x_test_onehot[x_train_onehot.columns]\n",
    "    \n",
    "    # Concatenate x_train and x_test with one-hot encoded columns\n",
    "    x_train = pd.concat([x_train, x_train_onehot], axis=1)\n",
    "    x_test = pd.concat([x_test, x_test_onehot], axis=1)\n",
    "\n",
    "    return x_train, x_test\n",
    "\n",
    "def numerical_rep(df):\n",
    "    df = df.copy()\n",
    "    y_dict = {'positive': 1, 'negative': -1, 'neutral': 0}\n",
    "    y = df.map(y_dict)\n",
    "    return y\n",
    "\n",
    "def inverse_numerical_rep(df):\n",
    "    df = df.copy()\n",
    "    y_dict = {'positive': 1, 'negative': -1, 'neutral': 0}\n",
    "    reverse_y_dict = {v: k for k, v in y_dict.items()} # Reverse the keys and values in y_dict\n",
    "    y = df.map(reverse_y_dict)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2dc8e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis_feature_selection(train, test, features='unigram'):\n",
    "    \"\"\"\n",
    "    parameter:\n",
    "        train,test: df\n",
    "        dataset being trained and tested on\n",
    "        features: String\n",
    "        which consists of customised features \"unigram,Tfidf,...\" splitted by \",\" \n",
    "    \n",
    "    returns:\n",
    "        x_train, x_test, y_train, y_test = DataFrame\n",
    "        only includes the data needed for training and test.\n",
    "    \"\"\"\n",
    "    # Customised\n",
    "    # Concatenate the original dataframe with the features selected\n",
    "    # Ignore upper/lower case, leading or trailing whitespaces\n",
    "    features_set = {'tfidf','unigram'}\n",
    "    customised_features_set = set(feature.strip().lower() for feature in features.split(\",\"))\n",
    "    if not customised_features_set.issubset(features_set):\n",
    "        raise ValueError(\"Please input with right features.\")\n",
    "\n",
    "    features_list = []\n",
    "    # Appending tuples at first\n",
    "    if 'tfidf' in customised_features_set:\n",
    "        features_list.append(feature_unigram(train, test))\n",
    "    if 'unigram' in customised_features_set:\n",
    "        features_list.append(feature_Tfidf(train, test))\n",
    "    # Unpacking\n",
    "    x_train_features = []\n",
    "    x_test_features = []\n",
    "    for x_train_feature, x_test_feature in features_list:\n",
    "        x_train_features.append(x_train_feature)\n",
    "        x_test_features.append(x_test_feature)\n",
    "    # convert to DataFrame\n",
    "    x_train = pd.concat(x_train_features, axis=1)\n",
    "    x_test = pd.concat(x_test_features, axis=1)\n",
    "    \n",
    "    # Default\n",
    "    # numerical representation of polarity\n",
    "    xy_train = dataframe_expansion(pd.concat([train, x_train], axis=1))\n",
    "    xy_test = dataframe_expansion(pd.concat([test, x_test], axis=1))\n",
    "    y_train = numerical_rep(xy_train['polarity'])\n",
    "    y_test = numerical_rep(xy_test['polarity'])\n",
    "    # label one-hotting\n",
    "    x_train, x_test = onehotting(xy_train, xy_test)\n",
    "    # Drop the original 'label' column from x_train and x_test\n",
    "    x_train.drop(train.columns.columns.values.tolist(), axis=1, inplace=True)\n",
    "    x_test.drop(test.columns.values.tolist(), axis=1, inplace=True)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d86f6a",
   "metadata": {},
   "source": [
    "## 2.4 Logistic Regression Classifer for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b4064b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_anaylysis_LogisticRegressionClf(features='unigram'):\n",
    "    \"\"\"\n",
    "        Train the classifer using selected data, make predictions on training data and \n",
    "        Generate classification report for training data\n",
    "        \n",
    "        parameter:        \n",
    "            features: String\n",
    "            which consists of customised features \"unigram,Tfidf,...\" splitted by \",\" \n",
    "            and will be used by the training of classifier\n",
    "    \"\"\"\n",
    "    Laptops_Train_p1 = parseXML(\"./data/Laptops_Train_p1.xml\")\n",
    "    Laptops_Test_p1_gold = parseXML(\"./data/Laptops_Test_p1_gold.xml\")\n",
    "\n",
    "    # Feature selection\n",
    "    x_train, x_test, y_train, y_test = sentiment_analysis_feature_selection(Laptops_Train_p1, Laptops_Test_p1_gold, features=features)\n",
    "        \n",
    "    # Create an instance of LogisticRegression\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    # Make predictions on training data\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    # Generate classification report for training data\n",
    "    classification_report_train = classification_report(y_test, y_pred)\n",
    "    print(\"Classification Report (Training Data):\\n\", classification_report_train)\n",
    "    \n",
    "    # Data format alignment\n",
    "    test_aligned = dataframe_undoexpansion(y_pred, Laptops_Test_p1_gold)\n",
    "    \n",
    "    return test_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fd67bd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laptops_Train_p1.xml has been parsed. The number of sentences with opinions is 2039(2500).\n",
      "Laptops_Test_p1_gold.xml has been parsed. The number of sentences with opinions is 808(808).\n",
      "Classification Report (Training Data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.66      0.68      0.67       274\n",
      "           0       0.33      0.07      0.11        46\n",
      "           1       0.79      0.84      0.81       481\n",
      "\n",
      "    accuracy                           0.74       801\n",
      "   macro avg       0.60      0.53      0.53       801\n",
      "weighted avg       0.72      0.74      0.72       801\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_aligned = sentiment_anaylysis_LogisticRegressionClf(features='unigram')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82085c87",
   "metadata": {},
   "source": [
    "# 3. Part 2 - Text-level Aspect Based Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ca0e22e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1f56e627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laptops_Train_p2.xml has been parsed. The number of reviews with opinions is 395(395).\n",
      "Laptops_Test_p2_gold.xml has been parsed. The number of reviews with opinions is 80(80).\n"
     ]
    }
   ],
   "source": [
    "Laptops_Train_p2 = parseXML_p2(\"./data/Laptops_Train_p2.xml\")\n",
    "Laptops_Test_p2_gold = parseXML_p2(\"./data/Laptops_Test_p2_gold.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1e68ef42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0074703CM_108_ANONYMOUS:0</td>\n",
       "      <td>Well, my first apple computer and I am impressed.</td>\n",
       "      <td>[LAPTOP#GENERAL]</td>\n",
       "      <td>[positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0074703CM_108_ANONYMOUS:1</td>\n",
       "      <td>Works well, fast and no reboots.</td>\n",
       "      <td>[LAPTOP#OPERATION_PERFORMANCE]</td>\n",
       "      <td>[positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0074703CM_108_ANONYMOUS:2</td>\n",
       "      <td>Waiting to install MS Office and see how it go...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0074703CM_108_ANONYMOUS:3</td>\n",
       "      <td>Have always been a PC guy, but decided to try ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0074703CM_108_ANONYMOUS:4</td>\n",
       "      <td>Glad I did so far.</td>\n",
       "      <td>[COMPANY#GENERAL, LAPTOP#GENERAL]</td>\n",
       "      <td>[positive, positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>B00L156USY_7_ANONYMOUS:2</td>\n",
       "      <td>When I attach a mouse it's fine but the touchp...</td>\n",
       "      <td>[MOUSE#USABILITY]</td>\n",
       "      <td>[negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>B00L156USY_7_ANONYMOUS:3</td>\n",
       "      <td>I went through the settings and there isn't a ...</td>\n",
       "      <td>[MOUSE#USABILITY]</td>\n",
       "      <td>[negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>B00L156USY_7_ANONYMOUS:4</td>\n",
       "      <td>Thinking I received the laptop with a faulty t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>B00L156USY_7_ANONYMOUS:5</td>\n",
       "      <td>If anyone can help me out on this, that would ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>B00L156USY_7_ANONYMOUS:6</td>\n",
       "      <td>It's a great laptop, but right now it's annoyi...</td>\n",
       "      <td>[LAPTOP#GENERAL, MOUSE#USABILITY]</td>\n",
       "      <td>[positive, positive]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>808 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Sentence ID  \\\n",
       "0    B0074703CM_108_ANONYMOUS:0   \n",
       "1    B0074703CM_108_ANONYMOUS:1   \n",
       "2    B0074703CM_108_ANONYMOUS:2   \n",
       "3    B0074703CM_108_ANONYMOUS:3   \n",
       "4    B0074703CM_108_ANONYMOUS:4   \n",
       "..                          ...   \n",
       "803    B00L156USY_7_ANONYMOUS:2   \n",
       "804    B00L156USY_7_ANONYMOUS:3   \n",
       "805    B00L156USY_7_ANONYMOUS:4   \n",
       "806    B00L156USY_7_ANONYMOUS:5   \n",
       "807    B00L156USY_7_ANONYMOUS:6   \n",
       "\n",
       "                                                  text  \\\n",
       "0    Well, my first apple computer and I am impressed.   \n",
       "1                     Works well, fast and no reboots.   \n",
       "2    Waiting to install MS Office and see how it go...   \n",
       "3    Have always been a PC guy, but decided to try ...   \n",
       "4                                   Glad I did so far.   \n",
       "..                                                 ...   \n",
       "803  When I attach a mouse it's fine but the touchp...   \n",
       "804  I went through the settings and there isn't a ...   \n",
       "805  Thinking I received the laptop with a faulty t...   \n",
       "806  If anyone can help me out on this, that would ...   \n",
       "807  It's a great laptop, but right now it's annoyi...   \n",
       "\n",
       "                                 label              polarity  \n",
       "0                     [LAPTOP#GENERAL]            [positive]  \n",
       "1       [LAPTOP#OPERATION_PERFORMANCE]            [positive]  \n",
       "2                                   []                    []  \n",
       "3                                   []                    []  \n",
       "4    [COMPANY#GENERAL, LAPTOP#GENERAL]  [positive, positive]  \n",
       "..                                 ...                   ...  \n",
       "803                  [MOUSE#USABILITY]            [negative]  \n",
       "804                  [MOUSE#USABILITY]            [negative]  \n",
       "805                                 []                    []  \n",
       "806                                 []                    []  \n",
       "807  [LAPTOP#GENERAL, MOUSE#USABILITY]  [positive, positive]  \n",
       "\n",
       "[808 rows x 4 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1c3afa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_to_text_level(df):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # Split the 'Sentence ID' column by ':' and only keep the first part\n",
    "    df['Sentence ID'] = df['Sentence ID'].apply(lambda x: x.split(':')[0])\n",
    "\n",
    "    # Group the rows by 'Sentence ID' and combine the 'label' and 'polarity' values into a list\n",
    "    grouped_df = df.groupby('Sentence ID',sort=False).agg({'label': lambda x: sum(x, []), 'polarity': lambda x: sum(x, [])})\n",
    "\n",
    "    # Reset the index to turn 'Sentence ID' back into a regular column\n",
    "    grouped_df = grouped_df.reset_index()\n",
    "\n",
    "    grouped_df = grouped_df.rename(columns={'Sentence ID': 'Review RID'})\n",
    "    \n",
    "    return grouped_df\n",
    "\n",
    "# def get_most_frequent_polarity_dict(df):\n",
    "    \n",
    "    \n",
    "def get_polarities_frequency_dict(rp):\n",
    "    frequency_distribution = Counter(row['polarity'])\n",
    "    return frequency_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2337eaed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review RID</th>\n",
       "      <th>label</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0074703CM_108_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#OPERATION_PERFORMANCE, COMPANY#GENERAL...</td>\n",
       "      <td>[positive, positive, positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00GJUQ4Z0_10_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#OPERATION_PERFORMANCE, LAPTOP#USABILIT...</td>\n",
       "      <td>[negative, negative, negative, negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0146DD02G_18_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#MISCELLANEOUS, LAPTOP#OPERATION_PERFOR...</td>\n",
       "      <td>[positive, positive, positive, positive, posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0074703CM_268_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#PRICE, LAPTOP#DESIGN_FEATURES, HARD_DI...</td>\n",
       "      <td>[positive, positive, positive, positive, posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0074703CM_240_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#QUALITY, LAPTOP#PRICE, DISPLAY#QUALITY...</td>\n",
       "      <td>[positive, positive, positive, positive, posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>B0074703CM_282_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#MISCELLANEOUS, SOFTWARE#OPERATION_PERF...</td>\n",
       "      <td>[negative, negative, negative, negative, negat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>B00LNFCADQ_5_ALWWKZCL1CKGD</td>\n",
       "      <td>[LAPTOP#CONNECTIVITY, SUPPORT#QUALITY, KEYBOAR...</td>\n",
       "      <td>[negative, negative, negative, negative, negat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>B0074703CM_6_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#PRICE, OS#GENERAL, COMPANY#GENERAL, OS...</td>\n",
       "      <td>[positive, positive, positive, positive, negat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>B0074703CM_173_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#PRICE, LAPTOP#OPERATION_PERFORMANCE, L...</td>\n",
       "      <td>[negative, positive, positive, positive, posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>B00L156USY_7_ANONYMOUS</td>\n",
       "      <td>[MOUSE#OPERATION_PERFORMANCE, MOUSE#USABILITY,...</td>\n",
       "      <td>[negative, negative, positive]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Review RID  \\\n",
       "0     B0074703CM_108_ANONYMOUS   \n",
       "1      B00GJUQ4Z0_10_ANONYMOUS   \n",
       "2      B0146DD02G_18_ANONYMOUS   \n",
       "3     B0074703CM_268_ANONYMOUS   \n",
       "4     B0074703CM_240_ANONYMOUS   \n",
       "..                         ...   \n",
       "75    B0074703CM_282_ANONYMOUS   \n",
       "76  B00LNFCADQ_5_ALWWKZCL1CKGD   \n",
       "77      B0074703CM_6_ANONYMOUS   \n",
       "78    B0074703CM_173_ANONYMOUS   \n",
       "79      B00L156USY_7_ANONYMOUS   \n",
       "\n",
       "                                                label  \\\n",
       "0   [LAPTOP#OPERATION_PERFORMANCE, COMPANY#GENERAL...   \n",
       "1   [LAPTOP#OPERATION_PERFORMANCE, LAPTOP#USABILIT...   \n",
       "2   [LAPTOP#MISCELLANEOUS, LAPTOP#OPERATION_PERFOR...   \n",
       "3   [LAPTOP#PRICE, LAPTOP#DESIGN_FEATURES, HARD_DI...   \n",
       "4   [LAPTOP#QUALITY, LAPTOP#PRICE, DISPLAY#QUALITY...   \n",
       "..                                                ...   \n",
       "75  [LAPTOP#MISCELLANEOUS, SOFTWARE#OPERATION_PERF...   \n",
       "76  [LAPTOP#CONNECTIVITY, SUPPORT#QUALITY, KEYBOAR...   \n",
       "77  [LAPTOP#PRICE, OS#GENERAL, COMPANY#GENERAL, OS...   \n",
       "78  [LAPTOP#PRICE, LAPTOP#OPERATION_PERFORMANCE, L...   \n",
       "79  [MOUSE#OPERATION_PERFORMANCE, MOUSE#USABILITY,...   \n",
       "\n",
       "                                             polarity  \n",
       "0                      [positive, positive, positive]  \n",
       "1            [negative, negative, negative, negative]  \n",
       "2   [positive, positive, positive, positive, posit...  \n",
       "3   [positive, positive, positive, positive, posit...  \n",
       "4   [positive, positive, positive, positive, posit...  \n",
       "..                                                ...  \n",
       "75  [negative, negative, negative, negative, negat...  \n",
       "76  [negative, negative, negative, negative, negat...  \n",
       "77  [positive, positive, positive, positive, negat...  \n",
       "78  [negative, positive, positive, positive, posit...  \n",
       "79                     [negative, negative, positive]  \n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Laptops_Test_p2_gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "109aa7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_level_ABSA(test_pred):\n",
    "    \n",
    "    grouped_sentence = group_to_text_level(test_pred)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c4eee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "985472fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence ID</th>\n",
       "      <th>label</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0074703CM_108_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#GENERAL, LAPTOP#OPERATION_PERFORMANCE,...</td>\n",
       "      <td>[positive, positive, positive, positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00GJUQ4Z0_10_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#OPERATION_PERFORMANCE, LAPTOP#OPERATIO...</td>\n",
       "      <td>[negative, negative, positive, negative, posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0146DD02G_18_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#GENERAL, LAPTOP#MISCELLANEOUS, LAPTOP#...</td>\n",
       "      <td>[positive, positive, positive, positive, posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0074703CM_268_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#PRICE, LAPTOP#GENERAL, LAPTOP#PRICE, L...</td>\n",
       "      <td>[positive, positive, neutral, negative, positi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0074703CM_240_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#PRICE, LAPTOP#GENERAL, DISPLAY#QUALITY...</td>\n",
       "      <td>[positive, positive, positive, positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>B0074703CM_282_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#MISCELLANEOUS, SOFTWARE#OPERATION_PERF...</td>\n",
       "      <td>[negative, negative, negative, negative, negat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>B00LNFCADQ_5_ALWWKZCL1CKGD</td>\n",
       "      <td>[LAPTOP#GENERAL, LAPTOP#GENERAL, LAPTOP#CONNEC...</td>\n",
       "      <td>[negative, negative, negative, negative, negat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>B0074703CM_6_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#PRICE, LAPTOP#GENERAL, LAPTOP#GENERAL,...</td>\n",
       "      <td>[positive, positive, negative, positive, posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>B0074703CM_173_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#GENERAL, LAPTOP#PRICE, LAPTOP#OPERATIO...</td>\n",
       "      <td>[negative, positive, positive, negative, negat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>B00L156USY_7_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#GENERAL, MOUSE#OPERATION_PERFORMANCE, ...</td>\n",
       "      <td>[positive, negative, negative, negative, negat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Sentence ID  \\\n",
       "0     B0074703CM_108_ANONYMOUS   \n",
       "1      B00GJUQ4Z0_10_ANONYMOUS   \n",
       "2      B0146DD02G_18_ANONYMOUS   \n",
       "3     B0074703CM_268_ANONYMOUS   \n",
       "4     B0074703CM_240_ANONYMOUS   \n",
       "..                         ...   \n",
       "75    B0074703CM_282_ANONYMOUS   \n",
       "76  B00LNFCADQ_5_ALWWKZCL1CKGD   \n",
       "77      B0074703CM_6_ANONYMOUS   \n",
       "78    B0074703CM_173_ANONYMOUS   \n",
       "79      B00L156USY_7_ANONYMOUS   \n",
       "\n",
       "                                                label  \\\n",
       "0   [LAPTOP#GENERAL, LAPTOP#OPERATION_PERFORMANCE,...   \n",
       "1   [LAPTOP#OPERATION_PERFORMANCE, LAPTOP#OPERATIO...   \n",
       "2   [LAPTOP#GENERAL, LAPTOP#MISCELLANEOUS, LAPTOP#...   \n",
       "3   [LAPTOP#PRICE, LAPTOP#GENERAL, LAPTOP#PRICE, L...   \n",
       "4   [LAPTOP#PRICE, LAPTOP#GENERAL, DISPLAY#QUALITY...   \n",
       "..                                                ...   \n",
       "75  [LAPTOP#MISCELLANEOUS, SOFTWARE#OPERATION_PERF...   \n",
       "76  [LAPTOP#GENERAL, LAPTOP#GENERAL, LAPTOP#CONNEC...   \n",
       "77  [LAPTOP#PRICE, LAPTOP#GENERAL, LAPTOP#GENERAL,...   \n",
       "78  [LAPTOP#GENERAL, LAPTOP#PRICE, LAPTOP#OPERATIO...   \n",
       "79  [LAPTOP#GENERAL, MOUSE#OPERATION_PERFORMANCE, ...   \n",
       "\n",
       "                                             polarity  \n",
       "0            [positive, positive, positive, positive]  \n",
       "1   [negative, negative, positive, negative, posit...  \n",
       "2   [positive, positive, positive, positive, posit...  \n",
       "3   [positive, positive, neutral, negative, positi...  \n",
       "4            [positive, positive, positive, positive]  \n",
       "..                                                ...  \n",
       "75  [negative, negative, negative, negative, negat...  \n",
       "76  [negative, negative, negative, negative, negat...  \n",
       "77  [positive, positive, negative, positive, posit...  \n",
       "78  [negative, positive, positive, negative, negat...  \n",
       "79  [positive, negative, negative, negative, negat...  \n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "50d7ef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_frequent_polarity_dist(row):\n",
    "    dict1 = {}\n",
    "    for key, value in zip(row['label'], row['polarity']):\n",
    "        if key in dict1:\n",
    "            dict1[key].append(value)\n",
    "        else:\n",
    "            dict1[key] = [value]\n",
    "    most_frequent_values = {}\n",
    "    for key, value_list in dict1.items():\n",
    "        most_frequent_values[key] = max(set(value_list), key=value_list.count)\n",
    "\n",
    "    return most_frequent_values\n",
    "\n",
    "df = group_to_text_level(test_aligned)\n",
    "df['most_frequent_polarity_dist'] = df.apply(get_most_frequent_polarity_dist, axis=1, result_type='expand')\n",
    "df['polarity_distribution'] = df.apply(get_polarities_frequency_dict, axis=1, result_type='expand')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "51ed2f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review RID</th>\n",
       "      <th>label</th>\n",
       "      <th>polarity</th>\n",
       "      <th>most_frequent_polarity_dist</th>\n",
       "      <th>polarity_distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0074703CM_108_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#GENERAL, LAPTOP#OPERATION_PERFORMANCE,...</td>\n",
       "      <td>[positive, positive, positive, positive]</td>\n",
       "      <td>{'LAPTOP#GENERAL': 'positive', 'LAPTOP#OPERATI...</td>\n",
       "      <td>{'positive': 4}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00GJUQ4Z0_10_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#OPERATION_PERFORMANCE, LAPTOP#OPERATIO...</td>\n",
       "      <td>[negative, negative, positive, negative, posit...</td>\n",
       "      <td>{'LAPTOP#OPERATION_PERFORMANCE': 'negative', '...</td>\n",
       "      <td>{'negative': 3, 'positive': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0146DD02G_18_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#GENERAL, LAPTOP#MISCELLANEOUS, LAPTOP#...</td>\n",
       "      <td>[positive, positive, positive, positive, posit...</td>\n",
       "      <td>{'LAPTOP#GENERAL': 'positive', 'LAPTOP#MISCELL...</td>\n",
       "      <td>{'positive': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0074703CM_268_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#PRICE, LAPTOP#GENERAL, LAPTOP#PRICE, L...</td>\n",
       "      <td>[positive, positive, neutral, negative, positi...</td>\n",
       "      <td>{'LAPTOP#PRICE': 'positive', 'LAPTOP#GENERAL':...</td>\n",
       "      <td>{'positive': 5, 'neutral': 1, 'negative': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0074703CM_240_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#PRICE, LAPTOP#GENERAL, DISPLAY#QUALITY...</td>\n",
       "      <td>[positive, positive, positive, positive]</td>\n",
       "      <td>{'LAPTOP#PRICE': 'positive', 'LAPTOP#GENERAL':...</td>\n",
       "      <td>{'positive': 4}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>B0074703CM_282_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#MISCELLANEOUS, SOFTWARE#OPERATION_PERF...</td>\n",
       "      <td>[negative, negative, negative, negative, negat...</td>\n",
       "      <td>{'LAPTOP#MISCELLANEOUS': 'negative', 'SOFTWARE...</td>\n",
       "      <td>{'negative': 11, 'positive': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>B00LNFCADQ_5_ALWWKZCL1CKGD</td>\n",
       "      <td>[LAPTOP#GENERAL, LAPTOP#GENERAL, LAPTOP#CONNEC...</td>\n",
       "      <td>[negative, negative, negative, negative, negat...</td>\n",
       "      <td>{'LAPTOP#GENERAL': 'negative', 'LAPTOP#CONNECT...</td>\n",
       "      <td>{'negative': 14}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>B0074703CM_6_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#PRICE, LAPTOP#GENERAL, LAPTOP#GENERAL,...</td>\n",
       "      <td>[positive, positive, negative, positive, posit...</td>\n",
       "      <td>{'LAPTOP#PRICE': 'positive', 'LAPTOP#GENERAL':...</td>\n",
       "      <td>{'positive': 10, 'negative': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>B0074703CM_173_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#GENERAL, LAPTOP#PRICE, LAPTOP#OPERATIO...</td>\n",
       "      <td>[negative, positive, positive, negative, negat...</td>\n",
       "      <td>{'LAPTOP#GENERAL': 'negative', 'LAPTOP#PRICE':...</td>\n",
       "      <td>{'negative': 5, 'positive': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>B00L156USY_7_ANONYMOUS</td>\n",
       "      <td>[LAPTOP#GENERAL, MOUSE#OPERATION_PERFORMANCE, ...</td>\n",
       "      <td>[positive, negative, negative, negative, negat...</td>\n",
       "      <td>{'LAPTOP#GENERAL': 'positive', 'MOUSE#OPERATIO...</td>\n",
       "      <td>{'positive': 3, 'negative': 5}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Review RID  \\\n",
       "0     B0074703CM_108_ANONYMOUS   \n",
       "1      B00GJUQ4Z0_10_ANONYMOUS   \n",
       "2      B0146DD02G_18_ANONYMOUS   \n",
       "3     B0074703CM_268_ANONYMOUS   \n",
       "4     B0074703CM_240_ANONYMOUS   \n",
       "..                         ...   \n",
       "75    B0074703CM_282_ANONYMOUS   \n",
       "76  B00LNFCADQ_5_ALWWKZCL1CKGD   \n",
       "77      B0074703CM_6_ANONYMOUS   \n",
       "78    B0074703CM_173_ANONYMOUS   \n",
       "79      B00L156USY_7_ANONYMOUS   \n",
       "\n",
       "                                                label  \\\n",
       "0   [LAPTOP#GENERAL, LAPTOP#OPERATION_PERFORMANCE,...   \n",
       "1   [LAPTOP#OPERATION_PERFORMANCE, LAPTOP#OPERATIO...   \n",
       "2   [LAPTOP#GENERAL, LAPTOP#MISCELLANEOUS, LAPTOP#...   \n",
       "3   [LAPTOP#PRICE, LAPTOP#GENERAL, LAPTOP#PRICE, L...   \n",
       "4   [LAPTOP#PRICE, LAPTOP#GENERAL, DISPLAY#QUALITY...   \n",
       "..                                                ...   \n",
       "75  [LAPTOP#MISCELLANEOUS, SOFTWARE#OPERATION_PERF...   \n",
       "76  [LAPTOP#GENERAL, LAPTOP#GENERAL, LAPTOP#CONNEC...   \n",
       "77  [LAPTOP#PRICE, LAPTOP#GENERAL, LAPTOP#GENERAL,...   \n",
       "78  [LAPTOP#GENERAL, LAPTOP#PRICE, LAPTOP#OPERATIO...   \n",
       "79  [LAPTOP#GENERAL, MOUSE#OPERATION_PERFORMANCE, ...   \n",
       "\n",
       "                                             polarity  \\\n",
       "0            [positive, positive, positive, positive]   \n",
       "1   [negative, negative, positive, negative, posit...   \n",
       "2   [positive, positive, positive, positive, posit...   \n",
       "3   [positive, positive, neutral, negative, positi...   \n",
       "4            [positive, positive, positive, positive]   \n",
       "..                                                ...   \n",
       "75  [negative, negative, negative, negative, negat...   \n",
       "76  [negative, negative, negative, negative, negat...   \n",
       "77  [positive, positive, negative, positive, posit...   \n",
       "78  [negative, positive, positive, negative, negat...   \n",
       "79  [positive, negative, negative, negative, negat...   \n",
       "\n",
       "                          most_frequent_polarity_dist  \\\n",
       "0   {'LAPTOP#GENERAL': 'positive', 'LAPTOP#OPERATI...   \n",
       "1   {'LAPTOP#OPERATION_PERFORMANCE': 'negative', '...   \n",
       "2   {'LAPTOP#GENERAL': 'positive', 'LAPTOP#MISCELL...   \n",
       "3   {'LAPTOP#PRICE': 'positive', 'LAPTOP#GENERAL':...   \n",
       "4   {'LAPTOP#PRICE': 'positive', 'LAPTOP#GENERAL':...   \n",
       "..                                                ...   \n",
       "75  {'LAPTOP#MISCELLANEOUS': 'negative', 'SOFTWARE...   \n",
       "76  {'LAPTOP#GENERAL': 'negative', 'LAPTOP#CONNECT...   \n",
       "77  {'LAPTOP#PRICE': 'positive', 'LAPTOP#GENERAL':...   \n",
       "78  {'LAPTOP#GENERAL': 'negative', 'LAPTOP#PRICE':...   \n",
       "79  {'LAPTOP#GENERAL': 'positive', 'MOUSE#OPERATIO...   \n",
       "\n",
       "                           polarity_distribution  \n",
       "0                                {'positive': 4}  \n",
       "1                 {'negative': 3, 'positive': 2}  \n",
       "2                                {'positive': 8}  \n",
       "3   {'positive': 5, 'neutral': 1, 'negative': 1}  \n",
       "4                                {'positive': 4}  \n",
       "..                                           ...  \n",
       "75               {'negative': 11, 'positive': 2}  \n",
       "76                              {'negative': 14}  \n",
       "77               {'positive': 10, 'negative': 1}  \n",
       "78                {'negative': 5, 'positive': 3}  \n",
       "79                {'positive': 3, 'negative': 5}  \n",
       "\n",
       "[80 rows x 5 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac737339",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 425.58333400000004,
   "position": {
    "height": "40px",
    "left": "1164.13px",
    "right": "20px",
    "top": "84px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
